# CXPlain: Causal Explanations for Model Interpretation under Uncertainty

Authors: *Patrick Schwab, Walter Karlen*  
Year: *2019*

## What this paper is about
A feature importance estimation method

## Why feature importance estimation is difficult

- There exists a wide variety of intricate machine learning models with different underlying model structures, algorithms, and decision functions, which change how it should be computed.
- Feature importance estimation is typically associated with significant uncertainty.

## What is awesome about the method

- It's accurate.
- It can be used for any type of machine learning model.
- It can express uncertainty well.
- It's fast in evaluation time.

## Main Idea
T.B.D

## Limitations
T.B.D

## Related Work
T.B.D


